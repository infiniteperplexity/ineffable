{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text Mining the Erowid Experience Vault"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### import packages and set path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Glenn\\Documents\\GitHub\\mining-erowid/\n"
     ]
    }
   ],
   "source": [
    "import os, sys, re, math\n",
    "path = os.path.abspath(\"\")+\"/\"\n",
    "print path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### generator to iterate files into memory as lists of words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import nltk, nltk.tokenize, nltk.corpus\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "def is_number(s):\n",
    "    try:\n",
    "        float(s)\n",
    "        return True\n",
    "    except ValueError:\n",
    "        return False\n",
    "\n",
    "def is_okay_word(s):\n",
    "    import re\n",
    "    if len(s)==1:\n",
    "        return False\n",
    "    elif is_number(s) and float(s)<1900:\n",
    "        return False\n",
    "    elif re.match('\\d+[mM]?[gGlLxX]',s):\n",
    "        return False\n",
    "    elif re.match('\\d+[oO][zZ]',s):\n",
    "        return False\n",
    "    else:\n",
    "        return True\n",
    "\n",
    "def yield_body_text(path):\n",
    "    stopwords = nltk.corpus.stopwords.words('english')\n",
    "    tokenizer = nltk.tokenize.RegexpTokenizer(r'\\w+')\n",
    "    tagger = nltk.tag.UnigramTagger(nltk.corpus.brown.tagged_sents())\n",
    "    lemmatizer = nltk.WordNetLemmatizer()\n",
    "    from nltk.corpus import wordnet\n",
    "    experiences = os.listdir(path+'xml')\n",
    "    for n, experience in enumerate(experiences):\n",
    "        #if n<9900:\n",
    "            #continue\n",
    "        #if n>10000:\n",
    "            #return\n",
    "        words = []\n",
    "        with open(path+\"xml/\"+experience) as file:\n",
    "            soup = BeautifulSoup(file)\n",
    "            #print experience\n",
    "            tokens = tokenizer.tokenize(soup.bodytext.contents[0])\n",
    "            pos = tagger.tag(tokens)\n",
    "            words = []\n",
    "            for token in pos:\n",
    "                if token[1] == 'NN':\n",
    "                    pos = wordnet.NOUN\n",
    "                elif token[1] == 'JJ':\n",
    "                    pos = wordnet.ADJ\n",
    "                elif token[1] == 'VB':\n",
    "                    pos = wordnet.VERB\n",
    "                elif token[1] == 'RV':\n",
    "                    pos = wordnet.ADV\n",
    "                else:\n",
    "                    pos = wordnet.NOUN\n",
    "                lemma = lemmatizer.lemmatize(token[0], pos)\n",
    "                if is_okay_word(lemma) and lemma not in stopwords:\n",
    "                    words.append(lemma)\n",
    "        if n%1000==0:\n",
    "            print(\"Finished \" + str(n) + \" files out of \" + str(len(experiences)))\n",
    "        yield \" \".join(words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## create the bag-of-words using CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished 0 files out of 19634\n",
      "Finished 1000 files out of 19634\n",
      "Finished 2000 files out of 19634\n",
      "Finished 3000 files out of 19634\n",
      "Finished 4000 files out of 19634\n",
      "Finished 5000 files out of 19634\n",
      "Finished 6000 files out of 19634\n",
      "Finished 7000 files out of 19634\n",
      "Finished 8000 files out of 19634\n",
      "Finished 9000 files out of 19634\n",
      "Finished 10000 files out of 19634\n",
      "Finished 11000 files out of 19634\n",
      "Finished 12000 files out of 19634\n",
      "Finished 13000 files out of 19634\n",
      "Finished 14000 files out of 19634\n",
      "Finished 15000 files out of 19634\n",
      "Finished 16000 files out of 19634\n",
      "Finished 17000 files out of 19634\n",
      "Finished 18000 files out of 19634\n",
      "Finished 19000 files out of 19634\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "cv = CountVectorizer(min_df=2)\n",
    "bag = cv.fit_transform(yield_body_text(path))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save or load the serialized matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "pickle.dump(bag, open(\"bag.p\",\"wb\"))\n",
    "#bag = pickle.load(open(\"bag.p\",\"rb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Determine feature weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "tf = TfidfTransformer()\n",
    "tfidf_bag = tf.fit_transform(bag)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.decomposition import TruncatedSVD\n",
    "svd = TruncatedSVD(n_components=100)\n",
    "svd_bag = svd.fit_transform(tfidf_bag)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get lists of important terms for each topic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def get_topic_names(model, vzr):\n",
    "    topics = []\n",
    "    for i in range(np.shape(model.components_)[0]):\n",
    "        weights = list(model.components_[i])\n",
    "        z = zip(weights,vzr.get_feature_names())\n",
    "        z.sort(reverse=True)\n",
    "        unzip = zip(*z)\n",
    "        topics.append(unzip[1])\n",
    "    return topics\n",
    "\n",
    "topics = get_topic_names(svd,cv)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(topics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(u'wa',\n",
       " u'like',\n",
       " u'time',\n",
       " u'felt',\n",
       " u'the',\n",
       " u'friend',\n",
       " u'would',\n",
       " u'it',\n",
       " u'one',\n",
       " u'trip',\n",
       " u'experience',\n",
       " u'could',\n",
       " u'we',\n",
       " u'back',\n",
       " u'feel',\n",
       " u'feeling',\n",
       " u'really',\n",
       " u'around',\n",
       " u'hour',\n",
       " u'get',\n",
       " u'started',\n",
       " u'thing',\n",
       " u'thought',\n",
       " u'day',\n",
       " u'my',\n",
       " u'effect',\n",
       " u'got',\n",
       " u'drug',\n",
       " u'still',\n",
       " u'went',\n",
       " u'much',\n",
       " u'go',\n",
       " u'first',\n",
       " u'took',\n",
       " u'night',\n",
       " u'room',\n",
       " u'this',\n",
       " u'minute',\n",
       " u'body',\n",
       " u'didn',\n",
       " u'good',\n",
       " u'little',\n",
       " u'people',\n",
       " u'going',\n",
       " u'life',\n",
       " u'everything',\n",
       " u'way',\n",
       " u'decided',\n",
       " u'began',\n",
       " u'eye',\n",
       " u'know',\n",
       " u'mind',\n",
       " u'even',\n",
       " u'something',\n",
       " u'take',\n",
       " u'think',\n",
       " u'see',\n",
       " u'seemed',\n",
       " u'never',\n",
       " u'point',\n",
       " u'high',\n",
       " u'also',\n",
       " u'looked',\n",
       " u'remember',\n",
       " u'two',\n",
       " u'pill',\n",
       " u'said',\n",
       " u'after',\n",
       " u'next',\n",
       " u'salvia',\n",
       " u'hit',\n",
       " u'though',\n",
       " u'made',\n",
       " u'house',\n",
       " u've',\n",
       " u'he',\n",
       " u'so',\n",
       " u'music',\n",
       " u'came',\n",
       " u'well',\n",
       " u'bit',\n",
       " u'told',\n",
       " u'tried',\n",
       " u'light',\n",
       " u'head',\n",
       " u'another',\n",
       " u'sleep',\n",
       " u'bed',\n",
       " u'anything',\n",
       " u'at',\n",
       " u'come',\n",
       " u'make',\n",
       " u'mushroom',\n",
       " u'try',\n",
       " u'ever',\n",
       " u'bad',\n",
       " u'wanted',\n",
       " u'later',\n",
       " u'knew',\n",
       " u'home',\n",
       " u'nothing',\n",
       " u'world',\n",
       " u'smoke',\n",
       " u'but',\n",
       " u'ha',\n",
       " u'every',\n",
       " u'water',\n",
       " u'quite',\n",
       " u'saw',\n",
       " u'found',\n",
       " u'wasn',\n",
       " u'say',\n",
       " u'couldn',\n",
       " u'year',\n",
       " u'2c',\n",
       " u'dose',\n",
       " u'almost',\n",
       " u'lot',\n",
       " u'right',\n",
       " u'long',\n",
       " u'away',\n",
       " u'since',\n",
       " u'pretty',\n",
       " u'visuals',\n",
       " u'getting',\n",
       " u'as',\n",
       " u'second',\n",
       " u'then',\n",
       " u'when',\n",
       " u'taking',\n",
       " u'half',\n",
       " u'left',\n",
       " u'smoked',\n",
       " u'seed',\n",
       " u'reality',\n",
       " u'last',\n",
       " u'intense',\n",
       " u'put',\n",
       " u'different',\n",
       " u'tripping',\n",
       " u'acid',\n",
       " u'didnt',\n",
       " u'and',\n",
       " u'looking',\n",
       " u'sat',\n",
       " u'hard',\n",
       " u'trying',\n",
       " u'completely',\n",
       " u'want',\n",
       " u'smoking',\n",
       " u'look',\n",
       " u'weed',\n",
       " u'kept',\n",
       " u'whole',\n",
       " u'sure',\n",
       " u'great',\n",
       " u'mg',\n",
       " u'many',\n",
       " u'became',\n",
       " u'face',\n",
       " u'car',\n",
       " u'done',\n",
       " u'thinking',\n",
       " u'im',\n",
       " u'happened',\n",
       " u'talking',\n",
       " u'finally',\n",
       " u'work',\n",
       " u'able',\n",
       " u'hand',\n",
       " u'part',\n",
       " u'start',\n",
       " u'week',\n",
       " u'place',\n",
       " u'real',\n",
       " u'bowl',\n",
       " u'lsd',\n",
       " u'kind',\n",
       " u'better',\n",
       " u'they',\n",
       " u'taken',\n",
       " u'state',\n",
       " u'noticed',\n",
       " u'normal',\n",
       " u'there',\n",
       " u'always',\n",
       " u'outside',\n",
       " u'actually',\n",
       " u'coming',\n",
       " u'small',\n",
       " u'in',\n",
       " u'find',\n",
       " u'however',\n",
       " u'morning',\n",
       " u'realized',\n",
       " u'new',\n",
       " u'sense',\n",
       " u'experienced',\n",
       " u'substance',\n",
       " u'stuff',\n",
       " u'enough',\n",
       " u'let',\n",
       " u'walk',\n",
       " u'probably',\n",
       " u'mdma',\n",
       " u'use',\n",
       " u'vision',\n",
       " u'soon',\n",
       " u'without',\n",
       " u'turned',\n",
       " u'everyone',\n",
       " u'asked',\n",
       " u'color',\n",
       " u'tell',\n",
       " u'three',\n",
       " u'month',\n",
       " u'maybe',\n",
       " u'walked',\n",
       " u'line',\n",
       " u'extremely',\n",
       " u'dream',\n",
       " u'wall',\n",
       " u'although',\n",
       " u'strange',\n",
       " u'side',\n",
       " u'idea',\n",
       " u'sort',\n",
       " u'yet',\n",
       " u'couple',\n",
       " u'best',\n",
       " u'gram',\n",
       " u'used',\n",
       " u'sitting',\n",
       " u'she',\n",
       " u'sound',\n",
       " u'all',\n",
       " u'energy',\n",
       " u'end',\n",
       " u'inside',\n",
       " u'school',\n",
       " u'strong',\n",
       " u'word',\n",
       " u'shrooms',\n",
       " u'stop',\n",
       " u'that',\n",
       " u'bathroom',\n",
       " u'heard',\n",
       " u'pot',\n",
       " u'walking',\n",
       " u'stomach',\n",
       " u'dont',\n",
       " u'someone',\n",
       " u'love',\n",
       " u'fun',\n",
       " u'heart',\n",
       " u'moment',\n",
       " u'closed',\n",
       " u'read',\n",
       " u'keep',\n",
       " u'seeing',\n",
       " u'pain',\n",
       " u'moving',\n",
       " u'help',\n",
       " u'pattern',\n",
       " u'far',\n",
       " u'else',\n",
       " u'suddenly',\n",
       " u'shit',\n",
       " u'full',\n",
       " u'floor',\n",
       " u'hallucination',\n",
       " u'happy',\n",
       " u'person',\n",
       " u'dmt',\n",
       " u'amazing',\n",
       " u'gone',\n",
       " u'talk',\n",
       " u'nausea',\n",
       " u'drink',\n",
       " u'might',\n",
       " u'amount',\n",
       " u'girlfriend',\n",
       " u'nice',\n",
       " u'rest',\n",
       " u'control',\n",
       " u'move',\n",
       " u'open',\n",
       " u'taste',\n",
       " u'definitely',\n",
       " u'door',\n",
       " u'asleep',\n",
       " u'fact',\n",
       " u'give',\n",
       " u'woke',\n",
       " u'entire',\n",
       " u'beautiful',\n",
       " u'dxm',\n",
       " u'party',\n",
       " u'movie',\n",
       " u'least',\n",
       " u'may',\n",
       " u'le',\n",
       " u'brain',\n",
       " u'mouth',\n",
       " u'god',\n",
       " u'big',\n",
       " u'gave',\n",
       " u'several',\n",
       " u'reason',\n",
       " u'weird',\n",
       " u'believe',\n",
       " u'eventually',\n",
       " u'for',\n",
       " u'watching',\n",
       " u'quickly',\n",
       " u'need',\n",
       " u'visual',\n",
       " u'slowly',\n",
       " u'problem',\n",
       " u'couldnt',\n",
       " u'slightly',\n",
       " u'call',\n",
       " u'report',\n",
       " u'lost',\n",
       " u'rather',\n",
       " u'marijuana',\n",
       " u'usually',\n",
       " u'couch',\n",
       " u'alcohol',\n",
       " u'seems',\n",
       " u'guy',\n",
       " u'bottle',\n",
       " u'pm',\n",
       " u'within',\n",
       " u'past',\n",
       " u'tree',\n",
       " u'saying',\n",
       " u'if',\n",
       " u'starting',\n",
       " u'now',\n",
       " u'what',\n",
       " u'll',\n",
       " u'fear',\n",
       " u'sensation',\n",
       " u'tea',\n",
       " u'hell',\n",
       " u'wasnt',\n",
       " u'close',\n",
       " u'longer',\n",
       " u'set',\n",
       " u'psychedelic',\n",
       " u'called',\n",
       " u'scared',\n",
       " u'tired',\n",
       " u'passed',\n",
       " u're',\n",
       " u'pipe',\n",
       " u'tv',\n",
       " u'needed',\n",
       " u'not',\n",
       " u'by',\n",
       " u'must',\n",
       " u'lay',\n",
       " u'seem',\n",
       " u'coke',\n",
       " u'mild',\n",
       " u'already',\n",
       " u'cold',\n",
       " u'old',\n",
       " u'interesting',\n",
       " u'ago',\n",
       " u'dark',\n",
       " u'become',\n",
       " u'using',\n",
       " u'parent',\n",
       " u'similar',\n",
       " u'large',\n",
       " u'front',\n",
       " u'change',\n",
       " u'fell',\n",
       " u'ate',\n",
       " u'alone',\n",
       " u'fine',\n",
       " u'together',\n",
       " u'sit',\n",
       " u'no',\n",
       " u'cigarette',\n",
       " u'eat',\n",
       " u'ended',\n",
       " u'voice',\n",
       " u'fast',\n",
       " u'making',\n",
       " u'slight',\n",
       " u'stopped',\n",
       " u'cannabis',\n",
       " u'turn',\n",
       " u'physical',\n",
       " u'plant',\n",
       " u'totally',\n",
       " u'buzz',\n",
       " u'peak',\n",
       " u'drinking',\n",
       " u'others',\n",
       " u'laughing',\n",
       " u'memory',\n",
       " u'arm',\n",
       " u'dos',\n",
       " u'chemical',\n",
       " u'level',\n",
       " u'anyone',\n",
       " u'ground',\n",
       " u'anyway',\n",
       " u'glass',\n",
       " u'mom',\n",
       " u'white',\n",
       " u'begin',\n",
       " u'wave',\n",
       " u'self',\n",
       " u'along',\n",
       " u'conversation',\n",
       " u'somewhat',\n",
       " u'seen',\n",
       " u'describe',\n",
       " u'leaf',\n",
       " u'euphoria',\n",
       " u'course',\n",
       " u'bong',\n",
       " u'about',\n",
       " u'hear',\n",
       " u'deep',\n",
       " u'mental',\n",
       " u'playing',\n",
       " u'sick',\n",
       " u'living',\n",
       " u'space',\n",
       " u'continued',\n",
       " u'lasted',\n",
       " u'man',\n",
       " u'ive',\n",
       " u'drank',\n",
       " u'universe',\n",
       " u'black',\n",
       " u'bag',\n",
       " u'understand',\n",
       " u'foot',\n",
       " u'girl',\n",
       " u'joint',\n",
       " u'immediately',\n",
       " u'relaxed',\n",
       " u'calm',\n",
       " u'talked',\n",
       " u'dosage',\n",
       " u'wrong',\n",
       " u'sober',\n",
       " u'sometimes',\n",
       " u'anxiety',\n",
       " u'cool',\n",
       " u'clear',\n",
       " u'computer',\n",
       " u'watch',\n",
       " u'notice',\n",
       " u'hospital',\n",
       " u'leave',\n",
       " u'mine',\n",
       " u'simply',\n",
       " u'pleasant',\n",
       " u'stay',\n",
       " u'breathing',\n",
       " u'crazy',\n",
       " u'etc',\n",
       " u'fucked',\n",
       " u'story',\n",
       " u'leg',\n",
       " u'ok',\n",
       " u'huge',\n",
       " u'drunk',\n",
       " u'short',\n",
       " u'warm',\n",
       " u'die',\n",
       " u'form',\n",
       " u'wouldn',\n",
       " u'stoned',\n",
       " u'bought',\n",
       " u'either',\n",
       " u'perhaps',\n",
       " u'happen',\n",
       " u'watched',\n",
       " u'spent',\n",
       " u'four',\n",
       " u'somehow',\n",
       " u'realize',\n",
       " u'mood',\n",
       " u'matter',\n",
       " u'difficult',\n",
       " u'mean',\n",
       " u'happening',\n",
       " u'on',\n",
       " u'except',\n",
       " u'note',\n",
       " u'aware',\n",
       " u'red',\n",
       " u'powder',\n",
       " u'doe',\n",
       " u'blue',\n",
       " u'ecstasy',\n",
       " u'exactly',\n",
       " u'evening',\n",
       " u'death',\n",
       " u'normally',\n",
       " u'behind',\n",
       " u'hold',\n",
       " u'beginning',\n",
       " u'due',\n",
       " u'fall',\n",
       " u'top',\n",
       " u'instead',\n",
       " u'meo',\n",
       " u'you',\n",
       " u'listening',\n",
       " u'ready',\n",
       " u'show',\n",
       " u'worse',\n",
       " u'usual',\n",
       " u'possible',\n",
       " u'five',\n",
       " u'green',\n",
       " u'opened',\n",
       " u'laid',\n",
       " u'brother',\n",
       " u'sky',\n",
       " u'anymore',\n",
       " u'boyfriend',\n",
       " u'across',\n",
       " u'food',\n",
       " u'telling',\n",
       " u'comfortable',\n",
       " u'enjoy',\n",
       " u'speed',\n",
       " u'reading',\n",
       " u'figured',\n",
       " u'phone',\n",
       " u'guess',\n",
       " u'rush',\n",
       " u'song',\n",
       " u'eating',\n",
       " u'air',\n",
       " u'consciousness',\n",
       " u'setting',\n",
       " u'awake',\n",
       " u'cocaine',\n",
       " u'explain',\n",
       " u'ran',\n",
       " u'to',\n",
       " u'human',\n",
       " u'positive',\n",
       " u'earlier',\n",
       " u'focus',\n",
       " u'drive',\n",
       " u'period',\n",
       " u'especially',\n",
       " u'heavy',\n",
       " u'street',\n",
       " u'changed',\n",
       " u'min',\n",
       " u'type',\n",
       " u'worth',\n",
       " u'opiate',\n",
       " u'straight',\n",
       " u'decide',\n",
       " u'moved',\n",
       " u'cause',\n",
       " u'image',\n",
       " u'while',\n",
       " u'low',\n",
       " u'brought',\n",
       " u'staring',\n",
       " u'panic',\n",
       " u'window',\n",
       " u'towards',\n",
       " u'game',\n",
       " u'beer',\n",
       " u'apartment',\n",
       " u'cup',\n",
       " u'often',\n",
       " u'play',\n",
       " u'amt',\n",
       " u'throughout',\n",
       " u'absolutely',\n",
       " u'powerful',\n",
       " u'held',\n",
       " u'upon',\n",
       " u'wonderful',\n",
       " u'piece',\n",
       " u'waiting',\n",
       " u'question',\n",
       " u'adderall',\n",
       " u'care',\n",
       " u'nutmeg',\n",
       " u'object',\n",
       " u'oh',\n",
       " u'overall',\n",
       " u'chair',\n",
       " u'shot',\n",
       " u'liquid',\n",
       " u'previous',\n",
       " u'negative',\n",
       " u'fairly',\n",
       " u'total',\n",
       " u'very',\n",
       " u'extract',\n",
       " u'mirror',\n",
       " u'its',\n",
       " u'horrible',\n",
       " u'wait',\n",
       " u'just',\n",
       " u'ride',\n",
       " u'higher',\n",
       " u'fuck',\n",
       " u'nature',\n",
       " u'slow',\n",
       " u'shape',\n",
       " u'hadn',\n",
       " u'hot',\n",
       " u'mostly',\n",
       " u'doctor',\n",
       " u'wake',\n",
       " u'kick',\n",
       " u'onto',\n",
       " u'live',\n",
       " u'waited',\n",
       " u'whatever',\n",
       " u'shower',\n",
       " u'ceiling',\n",
       " u'truly',\n",
       " u'running',\n",
       " u'perfect',\n",
       " u'managed',\n",
       " u'class',\n",
       " u'id',\n",
       " u'depression',\n",
       " u'complete',\n",
       " u'near',\n",
       " u'perception',\n",
       " u'psychedelics',\n",
       " u'capsule',\n",
       " u'nearly',\n",
       " u'easy',\n",
       " u'sudden',\n",
       " u'hope',\n",
       " u'pure',\n",
       " u'stood',\n",
       " u'headache',\n",
       " u'dancing',\n",
       " u'meth',\n",
       " u'family',\n",
       " u'case',\n",
       " u'arrived',\n",
       " u'pulled',\n",
       " u'cant',\n",
       " u'experiencing',\n",
       " u'funny',\n",
       " u'once',\n",
       " u'filled',\n",
       " u'true',\n",
       " u'breath',\n",
       " u'finished',\n",
       " u'ten',\n",
       " u'fucking',\n",
       " u'blood',\n",
       " u'run',\n",
       " u'test',\n",
       " u'store',\n",
       " u'touch',\n",
       " u'standing',\n",
       " u'sleeping',\n",
       " u'headed',\n",
       " u'euphoric',\n",
       " u'trouble',\n",
       " u'stronger',\n",
       " u'situation',\n",
       " u'skin',\n",
       " u'figure',\n",
       " u'rolling',\n",
       " u'helped',\n",
       " u'coffee',\n",
       " u'enjoyed',\n",
       " u'park',\n",
       " u'returned',\n",
       " u'incredible',\n",
       " u'stayed',\n",
       " u'am',\n",
       " u'given',\n",
       " u'recently',\n",
       " u'easily',\n",
       " u'dead',\n",
       " u'thats',\n",
       " u'field',\n",
       " u'sun',\n",
       " u'incredibly',\n",
       " u'falling',\n",
       " u'lying',\n",
       " u'bright',\n",
       " u'safe',\n",
       " u'learned',\n",
       " u'dad',\n",
       " u'uncomfortable',\n",
       " u'roll',\n",
       " u'barely',\n",
       " u'kid',\n",
       " u'muscle',\n",
       " u'odd',\n",
       " u'break',\n",
       " u'somewhere',\n",
       " u'name',\n",
       " u'hurt',\n",
       " u'doesn',\n",
       " u'extreme',\n",
       " u'gotten',\n",
       " u'paper',\n",
       " u'dry',\n",
       " u'deal',\n",
       " u'following',\n",
       " u'with',\n",
       " u'working',\n",
       " u'dance',\n",
       " u'empty',\n",
       " u'free',\n",
       " u'third',\n",
       " u'picture',\n",
       " u'stupid',\n",
       " u'confused',\n",
       " u'weekend',\n",
       " u'cry',\n",
       " u'area',\n",
       " u'mother',\n",
       " u'basically',\n",
       " u'experiment',\n",
       " u'prepared',\n",
       " u'knowing',\n",
       " u'cannot',\n",
       " u'nose',\n",
       " u'stand',\n",
       " u'important',\n",
       " u'journey',\n",
       " u'dropped',\n",
       " u'unable',\n",
       " u'worst',\n",
       " u'slept',\n",
       " u'middle',\n",
       " u'clock',\n",
       " u'driving',\n",
       " u'asking',\n",
       " u'tripped',\n",
       " u'ball',\n",
       " u'road',\n",
       " u'snorted',\n",
       " u'worried',\n",
       " u'heroin',\n",
       " u'group',\n",
       " u'event',\n",
       " u'hearing',\n",
       " u'alot',\n",
       " u'force',\n",
       " u'emotion',\n",
       " u'research',\n",
       " u'pass',\n",
       " u'nitrous',\n",
       " u'laying',\n",
       " u'attention',\n",
       " u'ketamine',\n",
       " u'certain',\n",
       " u'alive',\n",
       " u'process',\n",
       " u'fully',\n",
       " u'sounded',\n",
       " u'result',\n",
       " u'order',\n",
       " u'remembered',\n",
       " u'combination',\n",
       " u'reached',\n",
       " u'table',\n",
       " u'enjoyable',\n",
       " u'loved',\n",
       " u'writing',\n",
       " u'none',\n",
       " u'whether',\n",
       " u'cut',\n",
       " u'stuck',\n",
       " u'power',\n",
       " u'appeared',\n",
       " u'early',\n",
       " u'eaten',\n",
       " u'holding',\n",
       " u'proceeded',\n",
       " u'star',\n",
       " u'paranoid',\n",
       " u'kitchen',\n",
       " u'present',\n",
       " u'wood',\n",
       " u'attack',\n",
       " u'plan',\n",
       " u'cap',\n",
       " u'kinda',\n",
       " u'physically',\n",
       " u'today',\n",
       " u'user',\n",
       " u'general',\n",
       " u'nervous',\n",
       " u'fire',\n",
       " u'town',\n",
       " u'rolled',\n",
       " u'scary',\n",
       " u'forever',\n",
       " u'intensity',\n",
       " u'these',\n",
       " u'write',\n",
       " u'met',\n",
       " u'depressed',\n",
       " u'recommend',\n",
       " u'picked',\n",
       " u'soul',\n",
       " u'juice',\n",
       " u'worked',\n",
       " u'floating',\n",
       " u'stared',\n",
       " u'some',\n",
       " u'played',\n",
       " u'paranoia',\n",
       " u'throat',\n",
       " u'expected',\n",
       " u'online',\n",
       " u'threw',\n",
       " u'excited',\n",
       " u'tablet',\n",
       " u'convinced',\n",
       " u'wife',\n",
       " u'becoming',\n",
       " u'earth',\n",
       " u'spirit',\n",
       " u'grass',\n",
       " u'yes',\n",
       " u'dimension',\n",
       " u'money',\n",
       " u'afraid',\n",
       " u'unpleasant',\n",
       " u'imagine',\n",
       " u'noise',\n",
       " u'screen',\n",
       " u'twice',\n",
       " u'sister',\n",
       " u'late',\n",
       " u'laugh',\n",
       " u'roommate',\n",
       " u'mixed',\n",
       " u'movement',\n",
       " u'relax',\n",
       " u'leaving',\n",
       " u'known',\n",
       " u'material',\n",
       " u'laughed',\n",
       " u'handle',\n",
       " u'drove',\n",
       " u'corner',\n",
       " u'sitter',\n",
       " u'forward',\n",
       " u'ask',\n",
       " u'beyond',\n",
       " u'ego',\n",
       " u'finger',\n",
       " u'cloud',\n",
       " u'familiar',\n",
       " u'shaking',\n",
       " u'forget',\n",
       " u'isn',\n",
       " u'spiritual',\n",
       " u'lie',\n",
       " u'peace',\n",
       " u'attempt',\n",
       " u'constantly',\n",
       " u'pupil',\n",
       " u'book',\n",
       " u'single',\n",
       " u'various',\n",
       " u'mentally',\n",
       " u'existence',\n",
       " u'clean',\n",
       " u'enjoying',\n",
       " u'orange',\n",
       " u'ingested',\n",
       " u'listen',\n",
       " u'followed',\n",
       " u'speak',\n",
       " u'wonder',\n",
       " u'system',\n",
       " u'impossible',\n",
       " u'prior',\n",
       " u'okay',\n",
       " u'toilet',\n",
       " u'me',\n",
       " u'answer',\n",
       " u'certainly',\n",
       " u'lit',\n",
       " u'during',\n",
       " u'tolerance',\n",
       " u'step',\n",
       " u'throw',\n",
       " u'edge',\n",
       " u'return',\n",
       " u'vivid',\n",
       " u'loud',\n",
       " u'bedroom',\n",
       " u'buy',\n",
       " u'tasted',\n",
       " u'upstairs',\n",
       " u'chest',\n",
       " u'drop',\n",
       " u'caffeine',\n",
       " u'weren',\n",
       " u'insane',\n",
       " u'colour',\n",
       " u'rock',\n",
       " u'supposed',\n",
       " u'number',\n",
       " u'from',\n",
       " u'kicked',\n",
       " u'increased',\n",
       " u'dog',\n",
       " u'beat',\n",
       " u'expect',\n",
       " u'quality',\n",
       " u'college',\n",
       " u'cop',\n",
       " u'trail',\n",
       " u'recall',\n",
       " u'pick',\n",
       " u'overwhelming',\n",
       " u'everywhere',\n",
       " u'future',\n",
       " u'possibly',\n",
       " u'club',\n",
       " u'sex',\n",
       " u'smell',\n",
       " u'bring',\n",
       " u'dipt',\n",
       " u'six',\n",
       " u'clearly',\n",
       " u'direction',\n",
       " u'meaning',\n",
       " u'spot',\n",
       " u'interested',\n",
       " u'changing',\n",
       " u'herb',\n",
       " u'before',\n",
       " u'reaction',\n",
       " u'social',\n",
       " u'vomit',\n",
       " u'term',\n",
       " u'background',\n",
       " u'conclusion',\n",
       " u'lung',\n",
       " u'literally',\n",
       " u'caused',\n",
       " u'load',\n",
       " u'mistake',\n",
       " u'information',\n",
       " u'flower',\n",
       " u'ill',\n",
       " u'detail',\n",
       " u'random',\n",
       " u'terrible',\n",
       " u'despite',\n",
       " u'apparently',\n",
       " u'caught',\n",
       " u'lack',\n",
       " u'mescaline',\n",
       " u'non',\n",
       " u'desire',\n",
       " u'kratom',\n",
       " u'ability',\n",
       " u'wish',\n",
       " u'daily',\n",
       " u'cat',\n",
       " u'summer',\n",
       " u'stage',\n",
       " u'anxious',\n",
       " u'rate',\n",
       " u'afternoon',\n",
       " u'job',\n",
       " u'described',\n",
       " u'faster',\n",
       " u'gonna',\n",
       " u'chill',\n",
       " u'dried',\n",
       " u'view',\n",
       " u'urge',\n",
       " u'particular',\n",
       " u'mix',\n",
       " u'content',\n",
       " u'city',\n",
       " u'careful',\n",
       " ...)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topics[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#I can actually use gensim now...\n",
    "def doctext(path):\n",
    "\t\timport nltk, nltk.tokenize\n",
    "\t\ttokenizer = nltk.tokenize.RegexpTokenizer(r'\\w+')\n",
    "\t\tlemmatizer = nltk.WordNetLemmatizer()\n",
    "\t\tall_xml = os.listdir(path+'xml');\n",
    "\t\texperiences = [filename for filename in all_xml if re.match('\\d+.xml',filename)]\n",
    "\t\tfor n, experience in enumerate(experiences):\n",
    "\t\t\t#if n>100:\n",
    "\t\t\t\t#return\n",
    "\t\t\twith open(path+'xml/'+experience) as file:\n",
    "\t\t\t\tsoup = BeautifulSoup(file)\n",
    "\t\t\t\ttext = soup.bodytext.contents[0]\n",
    "\t\t\tif n%100==0:\n",
    "\t\t\t\tprint(\"Finished \" + str(n) + \" files out of \" + str(len(experiences)))\n",
    "\t\t\tyield text\n",
    "\n",
    "def is_number(s):\n",
    "\ttry:\n",
    "\t\tfloat(s)\n",
    "\t\treturn True\n",
    "\texcept ValueError:\n",
    "\t\treturn False\n",
    "\t\t\n",
    "def is_okay_word(word):\n",
    "\timport re\n",
    "\tif len(word)==1:\n",
    "\t\treturn False\n",
    "\telif is_number(word) and float(word)<1900:\n",
    "\t\treturn False\n",
    "\telif re.match('\\d+[mM]?[gGlLxX]',word):\n",
    "\t\treturn False\n",
    "\telif re.match('\\d+[oO][zZ]',word):\n",
    "\t\treturn False\n",
    "\telse:\n",
    "\t\treturn True\n",
    "\n",
    "def doctext(path):\n",
    "\t\tfrom nltk.corpus import stopwords\n",
    "\t\timport nltk, nltk.tokenize\n",
    "\t\ttokenizer = nltk.tokenize.RegexpTokenizer(r'\\w+')\n",
    "\t\tlemmatizer = nltk.WordNetLemmatizer()\n",
    "\t\tstopw = stopwords.words('english')\n",
    "\t\tall_xml = os.listdir(path+'xml');\n",
    "\t\texperiences = [filename for filename in all_xml if re.match('\\d+.xml',filename)]\n",
    "\t\tfor n, experience in enumerate(experiences):\n",
    "\t\t\t#if n>10:\n",
    "\t\t\t\t#return\n",
    "\t\t\twords = []\n",
    "\t\t\twith open(path+'xml/'+experience) as file:\n",
    "\t\t\t\tsoup = BeautifulSoup(file)\n",
    "\t\t\t\ttokens = tokenizer.tokenize(soup.bodytext.contents[0])\n",
    "\t\t\t\tlemmas = [lemmatizer.lemmatize(token.lower()) for token in tokens]\n",
    "\t\t\t\tfor lemma in lemmas:\n",
    "\t\t\t\t\tif is_okay_word(lemma) and lemma not in stopw:\n",
    "\t\t\t\t\t\twords.append(lemma)\t\n",
    "\t\t\tif n%100==0:\n",
    "\t\t\t\tprint(\"Finished \" + str(n) + \" files out of \" + str(len(experiences)))\n",
    "\t\t\tyield words\n",
    "\n",
    "if True:\n",
    "\tfrom gensim import corpora, models, similarities\n",
    "\tmypath = \"/home/glenn/Desktop/brainclouds/\"\n",
    "\tdictionary = corpora.Dictionary()\n",
    "\tcorpus = [dictionary.doc2bow(text, allow_update=True) for text in doctext(mypath)]\n",
    "\tdictionary.save(mypath+'bc_dict.dict')\n",
    "\tcorpora.MmCorpus.serialize(mypath+'bc_corpus.mm', corpus)\n",
    "\t\n",
    "if True:\n",
    "\tfrom gensim import corpora, models, similarities\n",
    "\tmypath = \"/home/glenn/Desktop/brainclouds/\"\n",
    "\tcorpus = corpora.MmCorpus(mypath+'bc_corpus.mm')\n",
    "\tdictionary = corpora.Dictionary.load(mypath+'bc_dict.dict')\n",
    "\t\n",
    "if True:\n",
    "\ttfidf = models.TfidfModel(corpus)\n",
    "\tcorpus_tfidf = tfidf[corpus]\n",
    "\n",
    "if True:\n",
    "\tlsi= models.ldamodel.LdaModel(corpus_tfidf, num_topics=100, id2word=dictionary)\n",
    "\tcorpus_lsi = lsi[corpus_tfidf]\n",
    "\n",
    "if True:\n",
    "\tlsi10 = models.ldamodel.LdaModel(corpus_tfidf, num_topics=10, id2word=dictionary)\n",
    "\tcorpus_lsi10 = lsi10[corpus_tfidf]\n",
    "\t\n",
    "if True:\n",
    "\tlda = models.ldamodel.LdaModel(corpus_tfidf, num_topics=100, id2word=dictionary)\n",
    "\tcorpus_lda = lda[corpus_tfidf]\n",
    "\t\n",
    "if True:\n",
    "\thdp = models.hdpmodel.HdpModel(corpus_tfidf, id2word=dictionary)\n",
    "\tcorpus_hdp = hdp(corpus_tfidf)\n",
    "\t\n",
    "if True:\n",
    "\tcorpora.MmCorpus.serialize(mypath+'bc_tfidf.mm', corpus_tfidf)\n",
    "\tcorpora.MmCorpus.serialize(mypath+'bc_lsi.mm', corpus_lsi)\n",
    "\tlsi10.save(mypath+'model.lsi10')\n",
    "\tlsi.save(mypath+'model.lsi')\n",
    "\ttfidf.save(mypath + 'model.tfidf')\n",
    "\t\n",
    "\t\n",
    "\tfrom gensim import corpora, models, similarities\n",
    "\tmypath = \"/home/glenn/Desktop/brainclouds/\"\n",
    "\tcorpus = corpora.MmCorpus(mypath+'bc_corpus.mm')\n",
    "\tdictionary = corpora.Dictionary.load(mypath+'bc_dict.dict')+'model.tfidf')\n",
    "\t\n",
    "if True:\n",
    "\tfrom gensim import corpora, models, similarities\n",
    "\tmypath = \"/home/glenn/Desktop/brainclouds/\"\n",
    "\tcorpus = corpora.MmCorpus(mypath+'bc_corpus.mm')\n",
    "\tdictionary = corpora.Dictionary.load(mypath+'bc_dict.dict')\n",
    "\tcorpus_tdif = corpora.MmCorpus(mypath+'bc_corpus.mm')\n",
    "\ttfidf = models.TfidfModel.load(mypath + 'model.tfidf')\n",
    "\tlsi = models.LsiModel.load(mypath+'model.lsi')\n",
    "\n",
    "if True:\n",
    "\timport gensim.matutils\n",
    "\tcorpus_matrix = gensim.matutils.corpus2csc(corpus).T\n",
    "\ttfidf_matrix = gensim.matutils.corpus2csc(corpus_tfidf).T\n",
    "\tlsi_matrix = gensim.matutils.corpus2csc(corpus_lsi).T\n",
    "\t\n",
    "if True:\n",
    "\tfrom sklearn.cluster import DBSCAN\n",
    "\tfrom sklearn.preprocessing import StandardScaler\n",
    "\tlsi_scaled = StandardScaler(with_mean=False).fit_transform(lsi_matrix)\n",
    "\tdb = DBSCAN().fit(lsi_scaled)\n",
    "\tcore_samples = db.core_sample_indices\n",
    "\tlabels = db.labels_"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
